{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Data loader** - Loading input data"
      ],
      "metadata": {
        "id": "590vuRGanRWO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx47uK4WnElj"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import requests\n",
        "if 'data_loader' not in globals():\n",
        "    from mage_ai.data_preparation.decorators import data_loader\n",
        "if 'test' not in globals():\n",
        "    from mage_ai.data_preparation.decorators import test\n",
        "\n",
        "\n",
        "@data_loader\n",
        "def load_data_from_api(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Template for loading data from API\n",
        "    \"\"\"\n",
        "    url = 'https://storage.googleapis.com/myfirstproject_uber/uber_data.csv'\n",
        "    response = requests.get(url)\n",
        "\n",
        "    return pd.read_csv(io.StringIO(response.text), sep=',')\n",
        "\n",
        "\n",
        "@test\n",
        "def test_output(output, *args) -> None:\n",
        "    \"\"\"\n",
        "    Template code for testing the output of the block.\n",
        "    \"\"\"\n",
        "    assert output is not None, 'The output is undefined'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformer** - Transforming input data"
      ],
      "metadata": {
        "id": "y-ng6hX1niSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "if 'transformer' not in globals():\n",
        "    from mage_ai.data_preparation.decorators import transformer\n",
        "if 'test' not in globals():\n",
        "    from mage_ai.data_preparation.decorators import test\n",
        "\n",
        "\n",
        "@transformer\n",
        "def transform(data, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Template code for a transformer block.\n",
        "\n",
        "    Add more parameters to this function if this block has multiple parent blocks.\n",
        "    There should be one parameter for each output variable from each parent block.\n",
        "\n",
        "    Args:\n",
        "        data: The output from the upstream parent block\n",
        "        args: The output from any additional upstream blocks (if applicable)\n",
        "\n",
        "    Returns:\n",
        "        Anything (e.g. data frame, dictionary, array, int, str, etc.)\n",
        "    \"\"\"\n",
        "    # Specify your transformation logic here\n",
        "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
        "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "    df = df.drop_duplicates().reset_index(drop=True)\n",
        "    df['trip_id'] = df.index\n",
        "    datetime_dm = df[['tpep_pickup_datetime','tpep_dropoff_datetime']].reset_index(drop=True)\n",
        "    datetime_dm['pickup_hour'] = datetime_dm['tpep_pickup_datetime'].dt.hour\n",
        "    datetime_dm['pickup_day'] = datetime_dm['tpep_pickup_datetime'].dt.day\n",
        "    datetime_dm['pickup_year'] = datetime_dm['tpep_pickup_datetime'].dt.year\n",
        "    datetime_dm['pickup_month'] = datetime_dm['tpep_pickup_datetime'].dt.month\n",
        "    datetime_dm['dropoff_hour'] = datetime_dm['tpep_dropoff_datetime'].dt.hour\n",
        "    datetime_dm['dropoff_day'] = datetime_dm['tpep_dropoff_datetime'].dt.day\n",
        "    datetime_dm['dropoff_year'] = datetime_dm['tpep_dropoff_datetime'].dt.year\n",
        "    datetime_dm['dropoff_month'] = datetime_dm['tpep_dropoff_datetime'].dt.month\n",
        "    datetime_dm['datetime_ID'] = datetime_dm.index\n",
        "\n",
        "    pickup_dm = df[['pickup_longitude','pickup_latitude']].reset_index(drop=True)\n",
        "    pickup_dm['pickup_ID'] = pickup_dm.index\n",
        "\n",
        "    dropoff_dm = df[['dropoff_longitude','dropoff_latitude']].reset_index(drop=True)\n",
        "    dropoff_dm['dropoff_ID'] = dropoff_dm.index\n",
        "\n",
        "    trip_distance_dm = df[['trip_distance']].reset_index(drop=True)\n",
        "    trip_distance_dm['trip_distance_ID'] = trip_distance_dm.index\n",
        "\n",
        "    ratecode_id_type =  {\n",
        "    1:\"Standard rate\",\n",
        "    2:\"JFK\",\n",
        "    3:\"Newark\",\n",
        "    4:\"Nassau or Westchester\",\n",
        "    5:\"Negotiated fare\",\n",
        "    6:\"Group ride\"\n",
        "    }\n",
        "    ratecode_dm = df[['RatecodeID']].reset_index(drop=True)\n",
        "    ratecode_dm['Ratecode_id'] = ratecode_dm.index\n",
        "    ratecode_dm['Ratecode_name'] = ratecode_dm['RatecodeID'].map(ratecode_id_type)\n",
        "\n",
        "    payment_id_type = {\n",
        "    1:\"Credit card\",\n",
        "    2:\"Cash\",\n",
        "    3:\"No charge\",\n",
        "    4:\"Dispute\",\n",
        "    5:\"Unknown\",\n",
        "    6:\"Voided trip\"\n",
        "    }\n",
        "    payment_dm = df[['payment_type']].reset_index(drop=True)\n",
        "    payment_dm['payment_ID'] = payment_dm.index\n",
        "    payment_dm['payment_name'] = payment_dm['payment_type'].map(payment_id_type)\n",
        "\n",
        "    datetime_dm = datetime_dm[['datetime_ID','tpep_pickup_datetime','pickup_hour','pickup_day', 'pickup_month','pickup_year', 'tpep_dropoff_datetime','dropoff_hour',\n",
        "       'dropoff_day','dropoff_month', 'dropoff_year' ]]\n",
        "\n",
        "    pickup_dm = pickup_dm[['pickup_ID','pickup_longitude','pickup_latitude']]\n",
        "\n",
        "    dropoff_dm = dropoff_dm[['dropoff_ID','dropoff_longitude','dropoff_latitude']]\n",
        "\n",
        "    ratecode_dm = ratecode_dm[['Ratecode_id','RatecodeID','Ratecode_name']]\n",
        "\n",
        "    payment_dm = payment_dm[['payment_ID','payment_type','payment_name']]\n",
        "\n",
        "    trip_distance_dm = trip_distance_dm[['trip_distance_ID','trip_distance']]\n",
        "\n",
        "    fact_table = df[['VendorID','passenger_count','store_and_fwd_flag','fare_amount','extra', 'mta_tax', 'tip_amount', 'tolls_amount','improvement_surcharge', 'total_amount', 'trip_id']].merge(datetime_dm, left_on = 'trip_id',right_on = 'datetime_ID').merge(payment_dm,left_on = 'trip_id',right_on = 'payment_ID').merge(trip_distance_dm,left_on = 'trip_id',right_on = 'trip_distance_ID').merge(ratecode_dm,left_on = 'trip_id',right_on = 'Ratecode_id').merge(dropoff_dm,left_on = 'trip_id',right_on = 'dropoff_ID').merge(pickup_dm,left_on = 'trip_id',right_on = 'pickup_ID')\n",
        "\n",
        "    fact_table = fact_table[['VendorID','pickup_ID','dropoff_ID','datetime_ID','payment_ID','Ratecode_id','trip_distance_ID','passenger_count','trip_distance','fare_amount','mta_tax','tip_amount','tolls_amount','improvement_surcharge','total_amount']]\n",
        "    # print(fact_table.head())\n",
        "\n",
        "\n",
        "    return {\"datetime_dm\":datetime_dm.to_dict(orient=\"dict\"),\n",
        "    \"pickup_dm\":pickup_dm.to_dict(orient=\"dict\"),\n",
        "    \"dropoff_dm\":dropoff_dm.to_dict(orient=\"dict\"),\n",
        "    \"ratecode_dm\":ratecode_dm.to_dict(orient=\"dict\"),\n",
        "    \"payment_dm\":payment_dm.to_dict(orient=\"dict\"),\n",
        "    \"trip_distance_dm\":trip_distance_dm.to_dict(orient=\"dict\"),\n",
        "    \"fact_table\":fact_table.to_dict(orient=\"dict\")}\n",
        "\n",
        "\n",
        "@test\n",
        "def test_output(output, *args) -> None:\n",
        "    \"\"\"\n",
        "    Template code for testing the output of the block.\n",
        "    \"\"\"\n",
        "    assert output is not None, 'The output is undefined'\n"
      ],
      "metadata": {
        "id": "AhFWGHSynj8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Exporter** - Big Query"
      ],
      "metadata": {
        "id": "6K-4WSQinjev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mage_ai.settings.repo import get_repo_path\n",
        "from mage_ai.io.bigquery import BigQuery\n",
        "from mage_ai.io.config import ConfigFileLoader\n",
        "from pandas import DataFrame\n",
        "from os import path\n",
        "\n",
        "if 'data_exporter' not in globals():\n",
        "    from mage_ai.data_preparation.decorators import data_exporter\n",
        "\n",
        "\n",
        "@data_exporter\n",
        "def export_data_to_big_query(data, **kwargs) -> None:\n",
        "    \"\"\"\n",
        "    Template for exporting data to a BigQuery warehouse.\n",
        "    Specify your configuration settings in 'io_config.yaml'.\n",
        "\n",
        "    Docs: https://docs.mage.ai/design/data-loading#bigquery\n",
        "    \"\"\"\n",
        "    config_path = path.join(get_repo_path(), 'io_config.yaml')\n",
        "    config_profile = 'default'\n",
        "\n",
        "    for key,value in data.items():\n",
        "\n",
        "        table_id = 'fit-visitor-393013.data_engineering_p1.{}'.format(key)\n",
        "        BigQuery.with_config(ConfigFileLoader(config_path, config_profile)).export(\n",
        "            DataFrame(value),\n",
        "            table_id,\n",
        "            if_exists='replace',  # Specify resolution policy if table name already exists\n",
        "        )\n"
      ],
      "metadata": {
        "id": "x5NHN2u4nkhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}